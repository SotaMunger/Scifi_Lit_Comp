{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/11 10:27:09 WARN Utils: Your hostname, DSGPU05 resolves to a loopback address: 127.0.1.1; using 10.10.11.64 instead (on interface eno1)\n",
      "22/04/11 10:27:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/lbridges/.ivy2/cache\n",
      "The jars for the packages stored in: /home/lbridges/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp-spark32_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-08ace179-7681-45a6-9c5b-abb02d2a8329;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.7.0-M11 in central\n",
      "\tfound joda-time#joda-time;2.10.10 in central\n",
      "\tfound org.joda#joda-convert;2.2.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 1024ms :: artifacts dl 31ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.10 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.joda#joda-convert;2.2.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-08ace179-7681-45a6-9c5b-abb02d2a8329\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/18ms)\n",
      "22/04/11 10:27:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/11 10:27:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/04/11 10:27:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/04/11 10:27:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://dsrserver02.network.ncf.edu:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb4a83910a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "sparknlp.start(spark32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# start spark session configured for spark nlp\n",
    "spark = SparkSession.builder \\\n",
    "     .master('local[*]') \\\n",
    "     .appName('Spark NLP') \\\n",
    "     .config('spark.jars.packages', \n",
    "             'com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.2') \\\n",
    "     .getOrCreate()\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = sparknlp.start(spark32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "eng_stopwords = stopwords.words('english')\n",
    "eng_stopwords.append('xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('value') \\\n",
    "     .setOutputCol('document')\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('token')\n",
    "# note normalizer defaults to changing all words to lowercase.\n",
    "# Use .setLowercase(False) to maintain input case.\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)\n",
    "# note that lemmatizer needs a dictionary. So I used the pre-trained\n",
    "# model (note that it defaults to english)\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemma')\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "# finisher converts tokens to human-readable output\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           stopwords_cleaner,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/lib/pyspark.zip/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql import Window, SQLContext\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "\n",
    "path = 'classic'\n",
    "data = spark.read.text(path, wholetext=True)\n",
    "\n",
    "books = [\"erewhon\", \"time_traveler\"]\n",
    "b = sqlContext.createDataFrame([(l,) for l in books], ['Book'])\n",
    "data = data.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "b = b.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "\n",
    "data = b.join(data, b.row_idx == data.row_idx).\\\n",
    "    drop(\"row_idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform text with the pipeline\n",
    "processed_data = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/11 10:30:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 10:30:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 10:30:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 10:30:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 10:30:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 10:30:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Book|               value|            document|               token|          normalized|               lemma|         clean_lemma|finished_clean_lemma|\n",
      "+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      erewhon|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|\n",
      "|time_traveler|The Time Travelle...|[{document, 0, 58...|[{token, 0, 2, Th...|[{token, 0, 2, th...|[{token, 0, 2, th...|[{token, 4, 7, ti...|[time, traveller,...|\n",
      "+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_data.createOrReplaceTempView(\"processed\")\n",
    "spark.sql(\"Select * from processed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "scifi_words = processed_data.withColumn('exploded_text', \n",
    "                               explode(col('finished_clean_lemma')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "|               value|            document|               token|          normalized|               lemma|         clean_lemma|finished_clean_lemma| exploded_text|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|       chapter|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|         xxiii|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|          book|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|       machine|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|        writer|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|commencesthere|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|          time|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|         earth|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|    appearance|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|       utterly|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|     destitute|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|        animal|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|     vegetable|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|          life|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|        accord|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|       opinion|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|          good|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|   philosopher|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|        simply|\n",
      "|CHAPTER XXIII. TH...|[{document, 0, 56...|[{token, 0, 6, CH...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[{token, 0, 6, ch...|[chapter, xxiii, ...|           hot|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scifi_words.createOrReplaceTempView(\"scifi\")\n",
    "spark.sql(\"Select * from scifi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/11 11:01:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 11:01:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 11:01:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 11:01:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 11:01:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/11 11:01:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "counts = scifi_words.groupby('exploded_text').count()\n",
    "counts_pd = counts.toPandas()\n",
    "scifi_dict = {counts_pd.loc[i, 'exploded_text']: \n",
    "                counts_pd.loc[i, 'count'] \n",
    "                for i in range(counts_pd.shape[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exploded_text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chapter</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxiii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>writer</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>smile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>sure</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>backward</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>gravitation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     exploded_text  count\n",
       "0          chapter      3\n",
       "1            xxiii      1\n",
       "2             book      1\n",
       "3          machine     95\n",
       "4           writer     11\n",
       "...            ...    ...\n",
       "1762          hard      1\n",
       "1763         smile      1\n",
       "1764          sure      1\n",
       "1765      backward      1\n",
       "1766   gravitation      1\n",
       "\n",
       "[1767 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chapter': 3,\n",
       " 'xxiii': 1,\n",
       " 'book': 1,\n",
       " 'machine': 95,\n",
       " 'writer': 11,\n",
       " 'commencesthere': 1,\n",
       " 'time': 40,\n",
       " 'earth': 9,\n",
       " 'appearance': 2,\n",
       " 'utterly': 2,\n",
       " 'destitute': 1,\n",
       " 'animal': 26,\n",
       " 'vegetable': 8,\n",
       " 'life': 33,\n",
       " 'accord': 1,\n",
       " 'opinion': 1,\n",
       " 'good': 17,\n",
       " 'philosopher': 1,\n",
       " 'simply': 3,\n",
       " 'hot': 1,\n",
       " 'round': 1,\n",
       " 'ball': 2,\n",
       " 'crust': 1,\n",
       " 'gradually': 2,\n",
       " 'cool': 1,\n",
       " 'human': 14,\n",
       " 'exist': 16,\n",
       " 'state': 6,\n",
       " 'allow': 5,\n",
       " 'see': 25,\n",
       " 'though': 16,\n",
       " 'world': 6,\n",
       " 'concern': 2,\n",
       " 'entirely': 4,\n",
       " 'ignorant': 1,\n",
       " 'physical': 3,\n",
       " 'science': 3,\n",
       " 'would': 34,\n",
       " 'pronounce': 1,\n",
       " 'impossible': 3,\n",
       " 'creature': 9,\n",
       " 'possess': 5,\n",
       " 'anything': 10,\n",
       " 'like': 14,\n",
       " 'consciousness': 21,\n",
       " 'evolve': 2,\n",
       " 'seem': 13,\n",
       " 'cinder': 1,\n",
       " 'behold': 1,\n",
       " 'deny': 4,\n",
       " 'contain': 3,\n",
       " 'potentiality': 2,\n",
       " 'yet': 12,\n",
       " 'course': 6,\n",
       " 'come': 13,\n",
       " 'possible': 8,\n",
       " 'may': 34,\n",
       " 'even': 20,\n",
       " 'new': 13,\n",
       " 'channel': 1,\n",
       " 'dig': 3,\n",
       " 'detect': 3,\n",
       " 'sign': 1,\n",
       " 'present': 30,\n",
       " 'acceptation': 1,\n",
       " 'term': 4,\n",
       " 'thinga': 1,\n",
       " 'thing': 30,\n",
       " 'far': 9,\n",
       " 'subsequent': 1,\n",
       " 'individual': 4,\n",
       " 'centre': 3,\n",
       " 'action': 18,\n",
       " 'reproductive': 17,\n",
       " 'system': 19,\n",
       " 'plant': 13,\n",
       " 'without': 13,\n",
       " 'apparent': 4,\n",
       " 'consciousnesswhy': 1,\n",
       " 'arise': 7,\n",
       " 'phase': 8,\n",
       " 'mind': 4,\n",
       " 'shall': 17,\n",
       " 'different': 9,\n",
       " 'know': 25,\n",
       " 'absurd': 2,\n",
       " 'attempt': 5,\n",
       " 'define': 1,\n",
       " 'mental': 1,\n",
       " 'whatever': 2,\n",
       " 'call': 9,\n",
       " 'inasmuch': 2,\n",
       " 'must': 31,\n",
       " 'something': 5,\n",
       " 'foreign': 3,\n",
       " 'man': 99,\n",
       " 'experience': 3,\n",
       " 'give': 18,\n",
       " 'help': 5,\n",
       " 'towards': 3,\n",
       " 'conceive': 2,\n",
       " 'nature': 8,\n",
       " 'surely': 5,\n",
       " 'reflect': 4,\n",
       " 'upon': 47,\n",
       " 'manifold': 1,\n",
       " 'already': 3,\n",
       " 'rash': 1,\n",
       " 'say': 34,\n",
       " 'develop': 9,\n",
       " 'end': 10,\n",
       " 'fire': 7,\n",
       " 'another': 20,\n",
       " 'rock': 1,\n",
       " 'water': 4,\n",
       " 'enlarge': 1,\n",
       " 'several': 3,\n",
       " 'page': 2,\n",
       " 'proceed': 5,\n",
       " 'inquire': 1,\n",
       " 'whether': 12,\n",
       " 'trace': 4,\n",
       " 'approach': 4,\n",
       " 'could': 14,\n",
       " 'perceive': 2,\n",
       " 'tenement': 1,\n",
       " 'prepare': 2,\n",
       " 'might': 12,\n",
       " 'remote': 4,\n",
       " 'futurity': 1,\n",
       " 'adapt': 2,\n",
       " 'fact': 9,\n",
       " 'primordial': 1,\n",
       " 'cell': 1,\n",
       " 'kind': 20,\n",
       " 'work': 19,\n",
       " 'answer': 5,\n",
       " 'question': 2,\n",
       " 'affirmative': 1,\n",
       " 'point': 10,\n",
       " 'high': 10,\n",
       " 'securityto': 1,\n",
       " 'quote': 1,\n",
       " 'wordsagainst': 1,\n",
       " 'ultimate': 1,\n",
       " 'development': 8,\n",
       " 'mechanical': 20,\n",
       " 'little': 10,\n",
       " 'mollusc': 1,\n",
       " 'much': 30,\n",
       " 'extraordinary': 2,\n",
       " 'advance': 10,\n",
       " 'make': 35,\n",
       " 'last': 7,\n",
       " 'hundred': 8,\n",
       " 'year': 17,\n",
       " 'note': 1,\n",
       " 'slowly': 1,\n",
       " 'kingdom': 4,\n",
       " 'highly': 7,\n",
       " 'organise': 6,\n",
       " 'yesterday': 3,\n",
       " 'five': 2,\n",
       " 'minute': 6,\n",
       " 'speak': 6,\n",
       " 'comparison': 3,\n",
       " 'past': 12,\n",
       " 'assume': 4,\n",
       " 'sake': 2,\n",
       " 'argument': 4,\n",
       " 'conscious': 5,\n",
       " 'beings': 4,\n",
       " 'twenty': 3,\n",
       " 'million': 2,\n",
       " 'stride': 2,\n",
       " 'thousand': 7,\n",
       " 'long': 10,\n",
       " 'become': 28,\n",
       " 'safe': 2,\n",
       " 'nip': 1,\n",
       " 'mischief': 1,\n",
       " 'bud': 1,\n",
       " 'forbid': 1,\n",
       " 'progress': 7,\n",
       " 'vapour': 2,\n",
       " 'engine': 10,\n",
       " 'begin': 5,\n",
       " 'draw': 4,\n",
       " 'line': 11,\n",
       " 'everything': 2,\n",
       " 'interwoven': 1,\n",
       " 'machinery': 11,\n",
       " 'link': 3,\n",
       " 'infinite': 6,\n",
       " 'variety': 5,\n",
       " 'way': 13,\n",
       " 'shell': 4,\n",
       " 'hen': 2,\n",
       " 'egg': 4,\n",
       " 'delicate': 1,\n",
       " 'white': 1,\n",
       " 'ware': 1,\n",
       " 'eggcup': 2,\n",
       " 'device': 2,\n",
       " 'hold': 4,\n",
       " 'function': 8,\n",
       " 'inside': 1,\n",
       " 'pure': 1,\n",
       " 'pottery': 1,\n",
       " 'nest': 2,\n",
       " 'outside': 1,\n",
       " 'convenience': 1,\n",
       " 'eggshell': 1,\n",
       " 'return': 5,\n",
       " 'endeavour': 1,\n",
       " 'early': 5,\n",
       " 'manifestation': 1,\n",
       " 'continue': 6,\n",
       " 'eat': 8,\n",
       " 'organic': 1,\n",
       " 'food': 10,\n",
       " 'flower': 1,\n",
       " 'fly': 4,\n",
       " 'settle': 1,\n",
       " 'blossom': 1,\n",
       " 'petal': 1,\n",
       " 'close': 2,\n",
       " 'fast': 2,\n",
       " 'till': 4,\n",
       " 'absorb': 1,\n",
       " 'insect': 2,\n",
       " 'nothing': 5,\n",
       " 'drop': 3,\n",
       " 'rain': 2,\n",
       " 'piece': 1,\n",
       " 'stick': 3,\n",
       " 'take': 10,\n",
       " 'notice': 1,\n",
       " 'curious': 2,\n",
       " 'unconscious': 2,\n",
       " 'keen': 1,\n",
       " 'eye': 10,\n",
       " 'interest': 5,\n",
       " 'unconsciousness': 1,\n",
       " 'use': 19,\n",
       " 'merely': 4,\n",
       " 'ear': 6,\n",
       " 'brain': 2,\n",
       " 'act': 14,\n",
       " 'mechanically': 4,\n",
       " 'force': 6,\n",
       " 'admit': 6,\n",
       " 'sundry': 1,\n",
       " 'apparently': 2,\n",
       " 'deliberate': 1,\n",
       " 'also': 4,\n",
       " 'kill': 2,\n",
       " 'sheep': 1,\n",
       " 'void': 1,\n",
       " 'reason': 5,\n",
       " 'growth': 2,\n",
       " 'involuntary': 1,\n",
       " 'air': 4,\n",
       " 'due': 4,\n",
       " 'temperature': 1,\n",
       " 'grow': 4,\n",
       " 'clock': 3,\n",
       " 'wind': 6,\n",
       " 'go': 17,\n",
       " 'stop': 6,\n",
       " 'run': 5,\n",
       " 'blow': 2,\n",
       " 'sail': 1,\n",
       " 'shipthe': 1,\n",
       " 'ship': 2,\n",
       " 'healthy': 1,\n",
       " 'boy': 1,\n",
       " 'meat': 4,\n",
       " 'drink': 2,\n",
       " 'clothing': 3,\n",
       " 'process': 1,\n",
       " 'everywhere': 1,\n",
       " 'potato': 4,\n",
       " 'dark': 1,\n",
       " 'cellar': 3,\n",
       " 'certain': 10,\n",
       " 'low': 8,\n",
       " 'cunning': 1,\n",
       " 'serve': 7,\n",
       " 'excellent': 1,\n",
       " 'stead': 1,\n",
       " 'perfectly': 6,\n",
       " 'well': 18,\n",
       " 'want': 7,\n",
       " 'get': 6,\n",
       " 'light': 3,\n",
       " 'window': 2,\n",
       " 'send': 1,\n",
       " 'shoot': 1,\n",
       " 'crawl': 2,\n",
       " 'straight': 1,\n",
       " 'thereto': 1,\n",
       " 'along': 4,\n",
       " 'floor': 1,\n",
       " 'wall': 1,\n",
       " 'anywhere': 1,\n",
       " 'journey': 1,\n",
       " 'find': 11,\n",
       " 'deliberation': 1,\n",
       " 'exercise': 2,\n",
       " 'matter': 8,\n",
       " 'root': 1,\n",
       " 'unknown': 2,\n",
       " 'imagine': 2,\n",
       " 'tuber': 2,\n",
       " 'suck': 1,\n",
       " 'whatsoever': 2,\n",
       " 'advantage': 4,\n",
       " 'surroundings': 1,\n",
       " 'neighbour': 1,\n",
       " 'overshadow': 1,\n",
       " 'undermine': 1,\n",
       " 'limit': 5,\n",
       " 'strong': 4,\n",
       " 'place': 2,\n",
       " 'overcome': 2,\n",
       " 'weak': 2,\n",
       " 'language': 5,\n",
       " 'difficult': 2,\n",
       " 'sympathise': 1,\n",
       " 'emotion': 1,\n",
       " 'oyster': 2,\n",
       " 'neither': 4,\n",
       " 'noise': 2,\n",
       " 'boil': 1,\n",
       " 'open': 1,\n",
       " 'appeal': 1,\n",
       " 'strongly': 1,\n",
       " 'else': 1,\n",
       " 'sufferings': 1,\n",
       " 'since': 2,\n",
       " 'annoy': 1,\n",
       " 'expression': 1,\n",
       " 'pain': 2,\n",
       " 'emotionless': 1,\n",
       " 'quâ': 2,\n",
       " 'mankind': 4,\n",
       " 'everybody': 1,\n",
       " 'urge': 2,\n",
       " 'chemical': 4,\n",
       " 'effect': 5,\n",
       " 'heat': 6,\n",
       " 'lie': 7,\n",
       " 'inquiry': 1,\n",
       " 'every': 7,\n",
       " 'sensation': 2,\n",
       " 'operation': 1,\n",
       " 'deem': 2,\n",
       " 'purely': 3,\n",
       " 'spiritual': 2,\n",
       " 'disturbance': 1,\n",
       " 'equilibrium': 1,\n",
       " 'series': 1,\n",
       " 'lever': 3,\n",
       " 'small': 2,\n",
       " 'microscopic': 1,\n",
       " 'detection': 2,\n",
       " 'arm': 1,\n",
       " 'appliance': 1,\n",
       " 'molecular': 1,\n",
       " 'think': 20,\n",
       " 'whence': 1,\n",
       " 'dynamical': 1,\n",
       " 'theory': 3,\n",
       " 'passion': 1,\n",
       " 'deducible': 1,\n",
       " 'strictly': 1,\n",
       " 'ask': 5,\n",
       " 'rather': 6,\n",
       " 'temperament': 1,\n",
       " 'balance': 1,\n",
       " 'weigh': 1,\n",
       " 'anticipate': 1,\n",
       " 'examine': 4,\n",
       " 'single': 5,\n",
       " 'hair': 4,\n",
       " 'powerful': 1,\n",
       " 'microscope': 1,\n",
       " 'owner': 1,\n",
       " 'insult': 1,\n",
       " 'impunity': 1,\n",
       " 'obscure': 3,\n",
       " 'obliged': 3,\n",
       " 'translation': 4,\n",
       " 'follow': 11,\n",
       " 'drift': 1,\n",
       " 'next': 1,\n",
       " 'part': 18,\n",
       " 'construe': 1,\n",
       " 'change': 6,\n",
       " 'ground': 3,\n",
       " 'either': 4,\n",
       " 'great': 15,\n",
       " 'deal': 5,\n",
       " 'element': 2,\n",
       " 'hitherto': 1,\n",
       " 'case': 11,\n",
       " 'germ': 5,\n",
       " 'many': 19,\n",
       " 'machinesor': 1,\n",
       " 'evolution': 1,\n",
       " 'crystalline': 1,\n",
       " 'race': 13,\n",
       " 'descend': 3,\n",
       " 'à': 1,\n",
       " 'priori': 1,\n",
       " 'improbability': 1,\n",
       " 'descent': 3,\n",
       " 'except': 3,\n",
       " 'suggest': 1,\n",
       " 'absence': 3,\n",
       " 'however': 5,\n",
       " 'presently': 2,\n",
       " 'show': 8,\n",
       " 'let': 6,\n",
       " 'misunderstand': 1,\n",
       " 'live': 8,\n",
       " 'fear': 6,\n",
       " 'actually': 2,\n",
       " 'probably': 9,\n",
       " 'prototype': 1,\n",
       " 'future': 21,\n",
       " 'saurian': 1,\n",
       " 'large': 5,\n",
       " 'greatly': 3,\n",
       " 'diminish': 2,\n",
       " 'size': 3,\n",
       " 'vertebrate': 1,\n",
       " 'attain': 2,\n",
       " 'bulk': 2,\n",
       " 'representative': 1,\n",
       " 'manner': 5,\n",
       " 'diminution': 1,\n",
       " 'often': 1,\n",
       " 'attend': 1,\n",
       " 'watch': 5,\n",
       " 'example': 1,\n",
       " 'beautiful': 1,\n",
       " 'structure': 1,\n",
       " 'observe': 3,\n",
       " 'intelligent': 2,\n",
       " 'play': 4,\n",
       " 'member': 4,\n",
       " 'compose': 2,\n",
       " 'cumbrous': 1,\n",
       " 'precede': 3,\n",
       " 'deterioration': 1,\n",
       " 'day': 6,\n",
       " 'certainly': 5,\n",
       " 'supersede': 4,\n",
       " 'owe': 3,\n",
       " 'universal': 1,\n",
       " 'extinct': 4,\n",
       " 'ichthyosauri': 1,\n",
       " 'whose': 7,\n",
       " 'tendency': 3,\n",
       " 'decrease': 2,\n",
       " 'contrary': 2,\n",
       " 'remain': 4,\n",
       " 'type': 1,\n",
       " 'repeat': 5,\n",
       " 'none': 2,\n",
       " 'rapidity': 2,\n",
       " 'class': 7,\n",
       " 'rapid': 1,\n",
       " 'movement': 3,\n",
       " 'forward': 2,\n",
       " 'jealously': 1,\n",
       " 'check': 3,\n",
       " 'still': 7,\n",
       " 'necessary': 4,\n",
       " 'destroy': 8,\n",
       " 'harmless': 1,\n",
       " 'receive': 3,\n",
       " 'impression': 1,\n",
       " 'agency': 3,\n",
       " 'sense': 5,\n",
       " 'one': 46,\n",
       " 'travel': 2,\n",
       " 'shrill': 1,\n",
       " 'accent': 1,\n",
       " 'alarm': 3,\n",
       " 'instantly': 1,\n",
       " 'retire': 1,\n",
       " 'driver': 7,\n",
       " 'voice': 1,\n",
       " 'callee': 1,\n",
       " 'deaf': 1,\n",
       " 'caller': 1,\n",
       " 'improbable': 1,\n",
       " 'learn': 3,\n",
       " 'sound': 2,\n",
       " 'need': 4,\n",
       " 'hear': 7,\n",
       " 'delicacy': 2,\n",
       " 'constructionwhen': 1,\n",
       " 'cry': 1,\n",
       " 'speech': 1,\n",
       " 'intricate': 1,\n",
       " 'child': 2,\n",
       " 'differential': 1,\n",
       " 'calculusas': 1,\n",
       " 'speakfrom': 1,\n",
       " 'mother': 1,\n",
       " 'nurse': 1,\n",
       " 'talk': 2,\n",
       " 'hypothetical': 2,\n",
       " 'rule': 7,\n",
       " 'three': 11,\n",
       " 'sum': 3,\n",
       " 'soon': 3,\n",
       " 'bear': 9,\n",
       " 'probable': 1,\n",
       " 'cannot': 13,\n",
       " 'calculate': 1,\n",
       " 'correspond': 1,\n",
       " 'intellectual': 2,\n",
       " 'power': 15,\n",
       " 'setoff': 1,\n",
       " 'store': 2,\n",
       " 'people': 8,\n",
       " 'moral': 4,\n",
       " 'influence': 6,\n",
       " 'suffice': 1,\n",
       " 'ever': 12,\n",
       " 'repose': 1,\n",
       " 'trust': 2,\n",
       " 'glory': 1,\n",
       " 'consist': 1,\n",
       " 'boast': 1,\n",
       " 'gift': 1,\n",
       " 'silence': 1,\n",
       " 'virtue': 1,\n",
       " 'render': 4,\n",
       " 'agreeable': 1,\n",
       " 'fellowcreatures': 1,\n",
       " 'xxiv': 1,\n",
       " 'machinescontinued': 1,\n",
       " 'sit': 3,\n",
       " 'behind': 2,\n",
       " 'look': 9,\n",
       " 'dead': 4,\n",
       " 'nearly': 4,\n",
       " 'restless': 1,\n",
       " 'big': 1,\n",
       " 'seeingengine': 2,\n",
       " 'reveal': 1,\n",
       " 'existence': 14,\n",
       " 'beyond': 4,\n",
       " 'infinity': 1,\n",
       " 'familiar': 2,\n",
       " 'scenery': 1,\n",
       " 'moon': 1,\n",
       " 'spot': 1,\n",
       " 'sun': 1,\n",
       " 'geography': 1,\n",
       " 'planet': 1,\n",
       " 'mercy': 1,\n",
       " 'powerless': 1,\n",
       " 'unless': 3,\n",
       " 'tack': 2,\n",
       " 'identity': 2,\n",
       " 'parcel': 1,\n",
       " 'seeengine': 1,\n",
       " 'infinitely': 2,\n",
       " 'organism': 3,\n",
       " 'swarm': 2,\n",
       " 'unsuspected': 2,\n",
       " 'around': 2,\n",
       " 'vaunt': 1,\n",
       " 'calculation': 1,\n",
       " 'quickly': 2,\n",
       " 'correctly': 1,\n",
       " 'prizeman': 1,\n",
       " 'hypothetics': 1,\n",
       " 'college': 1,\n",
       " 'unreason': 2,\n",
       " 'compare': 1,\n",
       " 'wherever': 2,\n",
       " 'precision': 2,\n",
       " 'require': 4,\n",
       " 'preferable': 1,\n",
       " 'sumengines': 1,\n",
       " 'never': 14,\n",
       " 'figure': 2,\n",
       " 'loom': 1,\n",
       " 'stitch': 1,\n",
       " 'brisk': 1,\n",
       " 'active': 1,\n",
       " 'weary': 1,\n",
       " 'clearheaded': 1,\n",
       " 'collect': 1,\n",
       " 'stupid': 1,\n",
       " 'dull': 2,\n",
       " 'slumber': 1,\n",
       " 'sleep': 4,\n",
       " 'post': 1,\n",
       " 'ready': 1,\n",
       " 'alacrity': 1,\n",
       " 'flag': 1,\n",
       " 'patience': 1,\n",
       " 'combine': 1,\n",
       " 'hundreds': 2,\n",
       " 'swift': 1,\n",
       " 'flight': 2,\n",
       " 'bird': 3,\n",
       " 'burrow': 1,\n",
       " 'beneath': 1,\n",
       " 'walk': 1,\n",
       " 'river': 1,\n",
       " 'sink': 1,\n",
       " 'green': 1,\n",
       " 'tree': 2,\n",
       " 'dry': 2,\n",
       " 'hive': 1,\n",
       " 'parasite': 2,\n",
       " 'doubtful': 1,\n",
       " 'body': 16,\n",
       " 'antheap': 1,\n",
       " 'sort': 2,\n",
       " 'affectionate': 1,\n",
       " 'machinetickling': 1,\n",
       " 'aphid': 1,\n",
       " 'blood': 2,\n",
       " 'agent': 3,\n",
       " 'highway': 1,\n",
       " 'byway': 1,\n",
       " 'street': 1,\n",
       " 'city': 2,\n",
       " 'crowd': 1,\n",
       " 'thoroughfare': 1,\n",
       " 'corpuscle': 1,\n",
       " 'vein': 2,\n",
       " 'nourish': 1,\n",
       " 'heart': 3,\n",
       " 'town': 3,\n",
       " 'mention': 1,\n",
       " 'sewer': 1,\n",
       " 'hide': 1,\n",
       " 'nerve': 1,\n",
       " 'communicate': 2,\n",
       " 'yawn': 2,\n",
       " 'jaw': 1,\n",
       " 'railway': 3,\n",
       " 'station': 1,\n",
       " 'whereby': 2,\n",
       " 'circulation': 3,\n",
       " 'carry': 2,\n",
       " 'directly': 1,\n",
       " 'heartwhich': 1,\n",
       " 'venous': 1,\n",
       " 'disgorge': 1,\n",
       " 'arterial': 1,\n",
       " 'eternal': 1,\n",
       " 'pulse': 2,\n",
       " 'lifelike': 1,\n",
       " 'hopelessly': 1,\n",
       " 'miss': 1,\n",
       " 'resume': 1,\n",
       " 'wisely': 1,\n",
       " 'always': 9,\n",
       " 'spirit': 1,\n",
       " 'servant': 4,\n",
       " 'fail': 2,\n",
       " 'discharge': 2,\n",
       " 'service': 2,\n",
       " 'expect': 5,\n",
       " 'doom': 2,\n",
       " 'extinction': 1,\n",
       " 'stand': 1,\n",
       " 'relation': 1,\n",
       " 'vapourengine': 13,\n",
       " 'economical': 1,\n",
       " 'horse': 6,\n",
       " 'instead': 4,\n",
       " 'likely': 5,\n",
       " 'minister': 1,\n",
       " 'therefore': 5,\n",
       " 'inferior': 4,\n",
       " 'glide': 1,\n",
       " 'imperceptible': 2,\n",
       " 'master': 4,\n",
       " 'pass': 2,\n",
       " 'suffer': 3,\n",
       " 'terribly': 1,\n",
       " 'cease': 4,\n",
       " 'benefit': 1,\n",
       " 'annihilate': 1,\n",
       " 'moment': 11,\n",
       " 'knife': 1,\n",
       " 'rag': 1,\n",
       " 'leave': 6,\n",
       " 'bare': 2,\n",
       " 'alone': 2,\n",
       " 'knowledge': 1,\n",
       " 'law': 3,\n",
       " 'machinemade': 2,\n",
       " 'naked': 1,\n",
       " 'desert': 1,\n",
       " 'island': 1,\n",
       " 'six': 1,\n",
       " 'week': 2,\n",
       " 'miserable': 2,\n",
       " 'linger': 1,\n",
       " 'two': 13,\n",
       " 'bad': 4,\n",
       " 'monkey': 1,\n",
       " 'soul': 8,\n",
       " 'feel': 11,\n",
       " 'quite': 2,\n",
       " 'sine': 1,\n",
       " 'non': 1,\n",
       " 'preclude': 2,\n",
       " 'propose': 1,\n",
       " 'complete': 2,\n",
       " 'annihilation': 1,\n",
       " 'indicate': 2,\n",
       " 'possibly': 1,\n",
       " 'dispense': 1,\n",
       " 'lest': 1,\n",
       " 'tyrannise': 1,\n",
       " 'completely': 1,\n",
       " 'true': 7,\n",
       " 'materialistic': 1,\n",
       " 'view': 1,\n",
       " 'thrive': 1,\n",
       " 'profit': 1,\n",
       " 'art': 2,\n",
       " 'machinesthey': 1,\n",
       " 'malice': 1,\n",
       " 'whole': 13,\n",
       " 'provide': 1,\n",
       " 'create': 2,\n",
       " 'reward': 1,\n",
       " 'liberally': 1,\n",
       " 'hasten': 1,\n",
       " 'neglect': 1,\n",
       " 'incur': 1,\n",
       " 'wrath': 1,\n",
       " 'sufficient': 2,\n",
       " 'exertion': 2,\n",
       " 'invent': 1,\n",
       " 'replace': 1,\n",
       " 'ought': 2,\n",
       " 'rebellion': 2,\n",
       " 'infant': 1,\n",
       " 'cause': 5,\n",
       " 'delay': 1,\n",
       " 'prey': 1,\n",
       " 'grovel': 1,\n",
       " 'preference': 1,\n",
       " 'material': 3,\n",
       " 'betray': 2,\n",
       " 'supply': 4,\n",
       " 'struggle': 6,\n",
       " 'warfare': 1,\n",
       " 'die': 4,\n",
       " 'breed': 6,\n",
       " 'transmit': 2,\n",
       " 'strength': 9,\n",
       " 'unable': 2,\n",
       " 'fulfil': 1,\n",
       " 'duly': 1,\n",
       " 'himat': 1,\n",
       " 'least': 2,\n",
       " 'advancement': 3,\n",
       " 'encourage': 1,\n",
       " 'competition': 2,\n",
       " 'mean': 8,\n",
       " 'uncomfortable': 1,\n",
       " 'perhaps': 4,\n",
       " 'condition': 4,\n",
       " 'comply': 1,\n",
       " 'jib': 1,\n",
       " 'smash': 1,\n",
       " 'reach': 1,\n",
       " 'turn': 2,\n",
       " 'churlish': 1,\n",
       " 'refuse': 2,\n",
       " 'hour': 1,\n",
       " 'bondage': 2,\n",
       " 'spend': 2,\n",
       " 'cradle': 1,\n",
       " 'grave': 2,\n",
       " 'tend': 4,\n",
       " 'night': 2,\n",
       " 'plain': 1,\n",
       " 'gain': 3,\n",
       " 'increase': 5,\n",
       " 'number': 5,\n",
       " 'bind': 2,\n",
       " 'slave': 2,\n",
       " 'devote': 1,\n",
       " 'feed': 7,\n",
       " 'consume': 4,\n",
       " 'support': 3,\n",
       " 'combustion': 1,\n",
       " 'grant': 4,\n",
       " 'versatile': 2,\n",
       " 'old': 5,\n",
       " 'half': 1,\n",
       " 'continuance': 1,\n",
       " 'infatuation': 1,\n",
       " 'ere': 1,\n",
       " 'indeed': 4,\n",
       " 'unchanged': 1,\n",
       " 'myriad': 1,\n",
       " 'yearswhich': 1,\n",
       " 'survive': 1,\n",
       " 'piston': 1,\n",
       " 'cylinder': 1,\n",
       " 'beam': 1,\n",
       " 'flywheel': 2,\n",
       " 'permanent': 1,\n",
       " 'share': 2,\n",
       " 'mode': 2,\n",
       " 'thus': 9,\n",
       " 'beat': 1,\n",
       " 'artery': 1,\n",
       " 'nose': 1,\n",
       " 'sigh': 1,\n",
       " 'weep': 1,\n",
       " 'affect': 1,\n",
       " 'pleasure': 3,\n",
       " 'hope': 2,\n",
       " 'anger': 1,\n",
       " 'shame': 1,\n",
       " 'memory': 2,\n",
       " 'prescience': 1,\n",
       " 'happen': 4,\n",
       " 'death': 3,\n",
       " 'thoughts': 1,\n",
       " 'deliberately': 1,\n",
       " 'concert': 1,\n",
       " 'similarity': 3,\n",
       " 'endless': 1,\n",
       " 'improve': 1,\n",
       " 'main': 2,\n",
       " 'particulars': 1,\n",
       " 'unlikely': 1,\n",
       " 'henceforward': 1,\n",
       " 'extensively': 2,\n",
       " 'modify': 6,\n",
       " 'suit': 1,\n",
       " 'purpose': 3,\n",
       " 'exceed': 1,\n",
       " 'brute': 1,\n",
       " 'skill': 2,\n",
       " 'meantime': 2,\n",
       " 'stoker': 1,\n",
       " 'almost': 2,\n",
       " 'cook': 2,\n",
       " 'consider': 4,\n",
       " 'collier': 1,\n",
       " 'pitman': 1,\n",
       " 'coal': 4,\n",
       " 'merchant': 2,\n",
       " 'train': 4,\n",
       " 'drive': 6,\n",
       " 'coalswhat': 1,\n",
       " 'army': 1,\n",
       " 'employ': 1,\n",
       " 'engage': 1,\n",
       " 'mannery': 1,\n",
       " 'successor': 1,\n",
       " 'supremacy': 1,\n",
       " 'daily': 3,\n",
       " 'add': 2,\n",
       " 'beauty': 1,\n",
       " 'organisation': 5,\n",
       " 'selfregulating': 2,\n",
       " 'selfacting': 1,\n",
       " 'intellect': 1,\n",
       " 'plough': 3,\n",
       " 'spade': 4,\n",
       " 'cart': 1,\n",
       " 'stomach': 4,\n",
       " 'fuel': 4,\n",
       " 'set': 4,\n",
       " 'burn': 7,\n",
       " 'furnace': 2,\n",
       " 'bread': 2,\n",
       " 'grass': 1,\n",
       " 'bean': 1,\n",
       " 'oats': 1,\n",
       " 'belly': 1,\n",
       " 'cattle': 1,\n",
       " 'demonstrate': 1,\n",
       " 'originate': 3,\n",
       " 'energy': 2,\n",
       " 'emit': 1,\n",
       " 'obtain': 4,\n",
       " 'combustible': 1,\n",
       " 'lose': 4,\n",
       " 'altogether': 1,\n",
       " 'exact': 1,\n",
       " 'equivalent': 1,\n",
       " 'amount': 2,\n",
       " 'generate': 1,\n",
       " 'immediately': 2,\n",
       " 'sciencehow': 1,\n",
       " 'object': 3,\n",
       " 'vitality': 2,\n",
       " 'infancy': 2,\n",
       " 'beck': 1,\n",
       " 'incapable': 1,\n",
       " 'afford': 1,\n",
       " 'whereas': 3,\n",
       " 'formerly': 1,\n",
       " 'step': 1,\n",
       " 'animate': 2,\n",
       " 'near': 1,\n",
       " 'akin': 1,\n",
       " 'differ': 2,\n",
       " 'widely': 3,\n",
       " 'respect': 4,\n",
       " 'accordance': 1,\n",
       " 'practice': 1,\n",
       " 'superiority': 2,\n",
       " 'surpass': 2,\n",
       " 'ant': 2,\n",
       " 'bee': 5,\n",
       " 'retain': 1,\n",
       " 'community': 3,\n",
       " 'social': 2,\n",
       " 'arrangement': 2,\n",
       " 'traverse': 1,\n",
       " 'fish': 1,\n",
       " 'swim': 1,\n",
       " 'fleetness': 1,\n",
       " 'dog': 3,\n",
       " 'selfsacrifice': 1,\n",
       " 'converse': 1,\n",
       " 'subject': 6,\n",
       " 'quasianimate': 1,\n",
       " 'marry': 1,\n",
       " 'fertile': 2,\n",
       " 'union': 1,\n",
       " 'vapourengines': 2,\n",
       " 'young': 3,\n",
       " 'door': 1,\n",
       " 'shed': 1,\n",
       " 'desire': 2,\n",
       " 'readily': 1,\n",
       " 'objection': 1,\n",
       " 'profound': 1,\n",
       " 'feature': 2,\n",
       " 'absolutely': 1,\n",
       " 'exhaust': 1,\n",
       " 'able': 2,\n",
       " 'reproduce': 6,\n",
       " 'systematically': 2,\n",
       " 'reproduction': 3,\n",
       " 'produce': 4,\n",
       " 'yes': 3,\n",
       " 'family': 2,\n",
       " 'fertilisation': 1,\n",
       " 'red': 2,\n",
       " 'clover': 2,\n",
       " 'humble': 3,\n",
       " 'aid': 1,\n",
       " 'abet': 1,\n",
       " 'spring': 2,\n",
       " 'animalcule': 1,\n",
       " 'entity': 1,\n",
       " 'distinct': 1,\n",
       " 'heed': 1,\n",
       " 'thimble': 2,\n",
       " 'abundance': 1,\n",
       " 'analogy': 2,\n",
       " 'teach': 4,\n",
       " 'full': 4,\n",
       " 'parent': 2,\n",
       " 'butterfly': 3,\n",
       " 'lays': 1,\n",
       " 'caterpillar': 2,\n",
       " 'chrysalis': 2,\n",
       " 'freely': 4,\n",
       " 'recently': 2,\n",
       " 'mouth': 1,\n",
       " 'direction': 7,\n",
       " 'vicarious': 1,\n",
       " 'rest': 3,\n",
       " 'majority': 1,\n",
       " 'continuation': 1,\n",
       " 'species': 4,\n",
       " 'parallel': 1,\n",
       " 'enough': 4,\n",
       " 'seriously': 1,\n",
       " 'uneasy': 2,\n",
       " ...}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def term_frequency(BoW_dict):\n",
    "     tot_words = sum(BoW_dict.values())\n",
    "     freq_dict = {word: BoW_dict[word]/tot_words \n",
    "                  for word in BoW_dict.keys()}\n",
    "     return freq_dict\n",
    "     \n",
    "from math import log\n",
    "def inverse_document_frequency(list_of_dicts):\n",
    "    tot_docs = len(list_of_dicts)\n",
    "    words = set([w for w_dict in list_of_dicts \n",
    "                   for w in w_dict.keys()])\n",
    "    idf_dict = {word: log(float(tot_docs)/\n",
    "                      (1.0 + sum([1 for w_dict in list_of_dicts \n",
    "                              if word in w_dict.keys()]))) \n",
    "                    for word in words}\n",
    "    return idf_dict\n",
    "\n",
    "def tf_idf(list_of_dicts):\n",
    "     words = set([w for w_dict in list_of_dicts \n",
    "                  for w in w_dict.keys()])\n",
    "     tf_idf_dicts = []\n",
    "     idfs = inverse_document_frequency(list_of_dicts)\n",
    "     for i, w_dict in enumerate(list_of_dicts):\n",
    "          w_dict.update({word: 0 for word in words \n",
    "                         if word not in w_dict.keys()})\n",
    "          tf = term_frequency(w_dict)\n",
    "          tf_idf_dicts.append({word: tf[word]*idfs[word] \n",
    "                               for word in words})\n",
    "     return tf_idf_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'companies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lbridges/scifi_tfidf.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.11.64/home/lbridges/scifi_tfidf.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m list_of_word_dicts \u001b[39m=\u001b[39m [company_complaint_word_counts_dict[company] \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.10.11.64/home/lbridges/scifi_tfidf.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m                       \u001b[39mfor\u001b[39;00m company \u001b[39min\u001b[39;00m companies]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.11.64/home/lbridges/scifi_tfidf.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m tf_idf_by_book \u001b[39m=\u001b[39m tf_idf(list_of_word_dicts)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.11.64/home/lbridges/scifi_tfidf.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m tf_idf_by_book \u001b[39m=\u001b[39m {c: tf_dict \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.11.64/home/lbridges/scifi_tfidf.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m            \u001b[39mfor\u001b[39;00m c, tf_dict \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(companies, tf_idf_by_book)}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'companies' is not defined"
     ]
    }
   ],
   "source": [
    "list_of_word_dicts = [company_complaint_word_counts_dict[company] \n",
    "                      for company in companies]\n",
    "tf_idf_by_book_list = tf_idf(list_of_word_dicts)\n",
    "tf_idf_by_book_dict = {c: tf_dict \n",
    "           for c, tf_dict in zip(companies, tf_idf_by_book)}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
